class MultiHeadAttention(nn.Module):
   def __init__(self):
       super(MultiHeadAttention, self).__init__()

   def forward(self, Q, K, V, attn_mask):
       pass